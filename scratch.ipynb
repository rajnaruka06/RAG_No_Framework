{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(pdf_file_path):\n",
    "    contents = []\n",
    "    doc = pymupdf.open(\"resume.pdf\")\n",
    "    for page in doc:\n",
    "        text = page.get_text()\n",
    "        contents.append(text)\n",
    "\n",
    "    return \"\\n\".join(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_pdf(\"resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Raj Kishor Naruka \\nPython | Data | Development \\nI am an aspiring Data Scientist with 1+ year experience as an Associate Business Analyst, skilled in data analysis, SQL, Python, AWS, machine learning,\\nand NLP. I am eager to leverage NLP, ML, and deep learning skills to contribute to a data-driven team. \\nrajnaruka0698@gmail.com \\n0403905464 \\nMelbourne, Australia \\nwww.kaggle.com/rajnaruka0698 \\nlinkedin.com/in/raj-naruka \\ngithub.com/rajnaruka06 \\nEDUCATION \\nMaster of Data Science \\nSwinburne University of Technology/ Melbourne \\n02/2023 - Present,  \\nBachelor of Technology (cse) \\nLovely Professional University/ Punjab \\n07/2016 - 06/2021,  \\n76.00% \\nPERSONAL PROJECTS \\nPrivacy Protector (08/2023 - 10/2023) \\nDeployed a Finetuned pretrained BERT on privacy policy documents on streamlit local to\\nclassify as acceptable or non acceptable with an f1 score of 0.86 \\nTechnologies used: Python, Transformers API from huggingface, sklearn, NLP, Streamlit \\nStoryGPT - Text Generation Model using GPT-2 Architecture\\n (04/2024 - 04/2024) \\nImplemented GPT-2 architecture from scratch (transformers, positional encoding) \\nFine-tuned pre-trained GPT-2 model (openai-community/gpt2) on short story dataset \\nDeployed as a user-friendly Streamlit app \\nWORK EXPERIENCE \\nAssociate Business Analyst(Business Technology Solutions\\nAssociate) \\nZS Associates \\n12/2021 - 12/2022,  \\nPune, India \\nCollaborated on building Snowﬂake data marts, contributing signiﬁcantly to design\\nand implementation. \\nDeveloped SQL scripts for generating Power BI reports, ensuring data accuracy and\\navailability. \\nAnalyzed Oracle database schema and views, optimizing and successfully migrating\\nthem to Snowﬂake for enhanced performance and eﬃciency. \\nJunior Data Scientist (Intern) \\nKulomb Mobilities Pvt. Ltd. \\n09/2020 - 12/2020,  \\nDesigned a MySQL database schema for eﬃcient data storage and retrieval. \\nImplemented Python code to simulate data environments and eﬃciently populate\\nthe MySQL database with dummy data for testing and development. \\nDeveloped machine learning models for tasks including clustering and customer\\nlifecycle prediction, contributing to data-driven decision-making processes. \\nSKILLS \\nPython \\nSQL \\nData Structures \\nProblem Solving \\nDatabase Systems \\nData analysis \\nMachine Learning \\nDeep Learning \\nAlgorithms \\nNLP \\nGen AI \\nAWS \\nACHIEVEMENTS \\nKaggle Notebooks Expert \\nKaggle is a platform for data scientists to practice and\\nshowcase their skills. \\n3 star coder on CodeChef (Competitive coding) \\nhttps://www.codechef.com/users/rajnaruka0698 \\nAmongst Top 10% coders on Leetcode \\nhttps://leetcode.com/rajnaruka0698/ \\nORGANIZATIONS \\nDepartment of Cultural Events\\n (06/2019 - 08/2019) \\nProtocol Manager (Operations) \\nDepartment Of Youth Capital (LPU)\\n (08/2019 - 09/2019) \\nTeam Lead (Operations) \\nCERTIFICATES \\nAmazon Web Services Cloud Practitioner\\n (06/2023 - 06/2026) \\nCredential ID: ZR41EFR2VE1EQCCW , Verify at:\\nhttps://aws.amazon.com/veriﬁcation \\nMachine Learning Specialization (06/2023) \\nhttps://coursera.org/verify/specialization/SJLF57FUBTW3 \\nDeep Learning Specialization (09/2023) \\nhttps://coursera.org/verify/specialization/L9EP8T7BTD8C \\nLANGUAGES \\nHindi \\nNative or Bilingual Proﬁciency \\nEnglish \\nFull Professional Proﬁciency \\nAchievements/Tasks \\nAchievements/Tasks \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for chunking the text into smaller parts\n",
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    end = chunk_size\n",
    "    while start < len(text):\n",
    "        chunks.append(text[start:end])\n",
    "        start = end - overlap\n",
    "        end = start + chunk_size\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raj Kishor Naruka \\nPython | Data | Development \\nI am an aspiring Data Scientist with 1+ year experie',\n",
       " 'ar experience as an Associate Business Analyst, skilled in data analysis, SQL, Python, AWS, machine ',\n",
       " ', machine learning,\\nand NLP. I am eager to leverage NLP, ML, and deep learning skills to contribute ',\n",
       " 'ontribute to a data-driven team. \\nrajnaruka0698@gmail.com \\n0403905464 \\nMelbourne, Australia \\nwww.kag',\n",
       " 'a \\nwww.kaggle.com/rajnaruka0698 \\nlinkedin.com/in/raj-naruka \\ngithub.com/rajnaruka06 \\nEDUCATION \\nMast',\n",
       " 'TION \\nMaster of Data Science \\nSwinburne University of Technology/ Melbourne \\n02/2023 - Present,  \\nBa',\n",
       " 'sent,  \\nBachelor of Technology (cse) \\nLovely Professional University/ Punjab \\n07/2016 - 06/2021,  \\n7',\n",
       " '/2021,  \\n76.00% \\nPERSONAL PROJECTS \\nPrivacy Protector (08/2023 - 10/2023) \\nDeployed a Finetuned pret',\n",
       " 'tuned pretrained BERT on privacy policy documents on streamlit local to\\nclassify as acceptable or no',\n",
       " 'able or non acceptable with an f1 score of 0.86 \\nTechnologies used: Python, Transformers API from hu',\n",
       " 'PI from huggingface, sklearn, NLP, Streamlit \\nStoryGPT - Text Generation Model using GPT-2 Architect',\n",
       " ' Architecture\\n (04/2024 - 04/2024) \\nImplemented GPT-2 architecture from scratch (transformers, posit',\n",
       " 'ers, positional encoding) \\nFine-tuned pre-trained GPT-2 model (openai-community/gpt2) on short story',\n",
       " 'hort story dataset \\nDeployed as a user-friendly Streamlit app \\nWORK EXPERIENCE \\nAssociate Business A',\n",
       " 'Business Analyst(Business Technology Solutions\\nAssociate) \\nZS Associates \\n12/2021 - 12/2022,  \\nPune,',\n",
       " '2,  \\nPune, India \\nCollaborated on building Snowﬂake data marts, contributing signiﬁcantly to design\\n',\n",
       " 'to design\\nand implementation. \\nDeveloped SQL scripts for generating Power BI reports, ensuring data ',\n",
       " 'ring data accuracy and\\navailability. \\nAnalyzed Oracle database schema and views, optimizing and succ',\n",
       " 'g and successfully migrating\\nthem to Snowﬂake for enhanced performance and eﬃciency. \\nJunior Data Sc',\n",
       " 'or Data Scientist (Intern) \\nKulomb Mobilities Pvt. Ltd. \\n09/2020 - 12/2020,  \\nDesigned a MySQL datab',\n",
       " 'ySQL database schema for eﬃcient data storage and retrieval. \\nImplemented Python code to simulate da',\n",
       " 'imulate data environments and eﬃciently populate\\nthe MySQL database with dummy data for testing and ',\n",
       " 'sting and development. \\nDeveloped machine learning models for tasks including clustering and custome',\n",
       " 'nd customer\\nlifecycle prediction, contributing to data-driven decision-making processes. \\nSKILLS \\nPy',\n",
       " 'SKILLS \\nPython \\nSQL \\nData Structures \\nProblem Solving \\nDatabase Systems \\nData analysis \\nMachine Lear',\n",
       " 'chine Learning \\nDeep Learning \\nAlgorithms \\nNLP \\nGen AI \\nAWS \\nACHIEVEMENTS \\nKaggle Notebooks Expert \\n',\n",
       " 's Expert \\nKaggle is a platform for data scientists to practice and\\nshowcase their skills. \\n3 star co',\n",
       " '\\n3 star coder on CodeChef (Competitive coding) \\nhttps://www.codechef.com/users/rajnaruka0698 \\nAmongs',\n",
       " '98 \\nAmongst Top 10% coders on Leetcode \\nhttps://leetcode.com/rajnaruka0698/ \\nORGANIZATIONS \\nDepartme',\n",
       " ' \\nDepartment of Cultural Events\\n (06/2019 - 08/2019) \\nProtocol Manager (Operations) \\nDepartment Of Y',\n",
       " 'tment Of Youth Capital (LPU)\\n (08/2019 - 09/2019) \\nTeam Lead (Operations) \\nCERTIFICATES \\nAmazon Web ',\n",
       " 'mazon Web Services Cloud Practitioner\\n (06/2023 - 06/2026) \\nCredential ID: ZR41EFR2VE1EQCCW , Verify',\n",
       " 'W , Verify at:\\nhttps://aws.amazon.com/veriﬁcation \\nMachine Learning Specialization (06/2023) \\nhttps:',\n",
       " '3) \\nhttps://coursera.org/verify/specialization/SJLF57FUBTW3 \\nDeep Learning Specialization (09/2023) ',\n",
       " '(09/2023) \\nhttps://coursera.org/verify/specialization/L9EP8T7BTD8C \\nLANGUAGES \\nHindi \\nNative or Bili',\n",
       " 've or Bilingual Proﬁciency \\nEnglish \\nFull Professional Proﬁciency \\nAchievements/Tasks \\nAchievements/',\n",
       " 'ievements/Tasks \\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_docs = chunk_text(docs, 100, 10)\n",
    "chunked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a vector representation for each chunk\n",
    "\n",
    "def create_embeddings(chunks, model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = []\n",
    "    for chunk in tqdm.tqdm(chunks, desc = \"Creating embeddings\"):\n",
    "        embeddings.append(model.encode(chunk, convert_to_tensor=True))\n",
    "    \n",
    "    ## Create embedding dict\n",
    "    embeddings_dict = {text : embedding for text, embedding in zip(chunks, embeddings)}\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name TinyLlama/TinyLlama-1.1B-Chat-v1.0. Creating a new one with mean pooling.\n",
      "Creating embeddings:   0%|          | 0/37 [00:00<?, ?it/s]c:\\Users\\rajna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:670: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Creating embeddings: 100%|██████████| 37/37 [00:01<00:00, 29.27it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = create_embeddings(chunked_docs)\n",
    "torch.save(embeddings, \"embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve top k similar chunks\n",
    "\n",
    "def retrieve_topk_similar(query, embeddings, k=5, model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    similarities = {}\n",
    "    for text, embedding in embeddings.items():\n",
    "        cos_sim = torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), embedding.unsqueeze(0))\n",
    "        # cos_sim = torch.nn.functional.cosine_similarity(query_embedding, embedding)\n",
    "        similarities[text] = cos_sim.item()\n",
    "    \n",
    "    topk_similar = sorted(similarities.items(), key = lambda x: x[1], reverse = True)[:k]\n",
    "    return [text for text, score in topk_similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name TinyLlama/TinyLlama-1.1B-Chat-v1.0. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ar experience as an Associate Business Analyst, skilled in data analysis, SQL, Python, AWS, machine ',\n",
       " 'sting and development. \\nDeveloped machine learning models for tasks including clustering and custome',\n",
       " 'to design\\nand implementation. \\nDeveloped SQL scripts for generating Power BI reports, ensuring data ',\n",
       " ', machine learning,\\nand NLP. I am eager to leverage NLP, ML, and deep learning skills to contribute ',\n",
       " 'imulate data environments and eﬃciently populate\\nthe MySQL database with dummy data for testing and ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the skills of the candidate?\"\n",
    "topk_similar = retrieve_topk_similar(query, embeddings)\n",
    "topk_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create context to pass to the LLM model\n",
    "\n",
    "def create_context(query, topk_similar):\n",
    "    context = [f\"Document{idx}: {text}\" for idx, text in enumerate(topk_similar, 1)]\n",
    "    context = \" \".join(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document1: ar experience as an Associate Business Analyst, skilled in data analysis, SQL, Python, AWS, machine  Document2: sting and development. \\nDeveloped machine learning models for tasks including clustering and custome Document3: to design\\nand implementation. \\nDeveloped SQL scripts for generating Power BI reports, ensuring data  Document4: , machine learning,\\nand NLP. I am eager to leverage NLP, ML, and deep learning skills to contribute  Document5: imulate data environments and eﬃciently populate\\nthe MySQL database with dummy data for testing and '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = create_context(query, topk_similar)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt the LLM model\n",
    "\n",
    "prompt = \"\"\"Please answer the following question based on the given context.\n",
    "context: {context}\n",
    "question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use LLM to answer the question\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def answer_question(query, context, model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"):\n",
    "    qa_pipeline = pipeline(\"text-generation\", model=model_name)\n",
    "    messgae = prompt.format(context = context, query = query)\n",
    "    answer = qa_pipeline(messgae, max_length=1000)[0][\"generated_text\"]\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The candidate has experience as an Associate Business Analyst, skilled in data analysis, SQL, Python, AWS, machine learning, and NLP. They have developed machine learning models for tasks including clustering and customization, developed SQL scripts for generating Power BI reports, ensuring data quality, and leveraging NLP, ML, and deep learning skills to contribute to the development of data environments and efficiently populate the MySQL database with dummy data for testing and evaluation.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the skills of the candidate?\"\n",
    "ans  = answer_question(query, context)\n",
    "ans = ans.split(\"answer:\")[1].strip()\n",
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
